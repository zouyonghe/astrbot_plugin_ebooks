import asyncio
import io
import random
import re
import xml.etree.ElementTree as ET
from datetime import datetime
from typing import Optional
from urllib.parse import quote_plus, urljoin, unquote, urlparse
from PIL import Image as Img

import aiofiles
import aiohttp
from aiohttp import ClientPayloadError
from bs4 import BeautifulSoup

from data.plugins.astrbot_plugin_ebooks.Zlibrary import Zlibrary
from astrbot.api.all import *
from astrbot.api.event.filter import *


@register("ebooks", "buding", "ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ç”µå­ä¹¦æœç´¢å’Œä¸‹è½½æ’ä»¶", "1.0.2", "https://github.com/zouyonghe/astrbot_plugin_ebooks")
class ebooks(Star):
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config
        self.proxy = os.environ.get("https_proxy")
        self.TEMP_PATH = os.path.abspath("data/temp")
        os.makedirs(self.TEMP_PATH, exist_ok=True)
        self.zlibrary = None

    async def is_url_accessible(self, url: str) -> bool:
        """
        å¼‚æ­¥æ£€æŸ¥ç»™å®šçš„ URL æ˜¯å¦å¯è®¿é—®ã€‚

        :param url: è¦æ£€æŸ¥çš„ URL
        :return: å¦‚æœ URL å¯è®¿é—®è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
        """
        try:
            async with aiohttp.ClientSession() as session:
                async with session.head(url, timeout=3, proxy=self.proxy, allow_redirects=True) as response:
                    return response.status == 200  # è¿”å›çŠ¶æ€æ˜¯å¦ä¸º 200
        except:
            return False  # å¦‚æœè¯·æ±‚å¤±è´¥ï¼ˆè¶…æ—¶ã€è¿æ¥ä¸­æ–­ç­‰ï¼‰åˆ™è¿”å› False

    async def download_and_convert_to_base64(self, cover_url):
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(cover_url, proxy=self.proxy) as response:
                    if response.status != 200:
                        return None

                    content_type = response.headers.get('Content-Type', '').lower()
                    # å¦‚æœ Content-Type åŒ…å« htmlï¼Œåˆ™è¯´æ˜å¯èƒ½ä¸æ˜¯ç›´æ¥çš„å›¾ç‰‡
                    if 'html' in content_type:
                        html_content = await response.text()
                        # ä½¿ç”¨ BeautifulSoup æå–å›¾ç‰‡åœ°å€
                        soup = BeautifulSoup(html_content, 'html.parser')
                        img_tag = soup.find('meta', attrs={'property': 'og:image'})
                        if img_tag:
                            cover_url = img_tag.get('content')
                            # å†æ¬¡å°è¯•ä¸‹è½½çœŸæ­£çš„å›¾ç‰‡åœ°å€
                            return await self.download_and_convert_to_base64(cover_url)
                        else:
                            return None

                    # å¦‚æœæ˜¯å›¾ç‰‡å†…å®¹ï¼Œç»§ç»­ä¸‹è½½å¹¶è½¬ä¸º Base64
                    content = await response.read()
                    base64_data = base64.b64encode(content).decode("utf-8")
                    return base64_data
        except ClientPayloadError as payload_error:
            # å°è¯•å·²æ¥æ”¶çš„æ•°æ®éƒ¨åˆ†
            if 'content' in locals():  # å¦‚æœéƒ¨åˆ†å†…å®¹å·²ä¸‹è½½
                base64_data = base64.b64encode(content).decode("utf-8")
                if self.is_base64_image(base64_data):  # æ£€æŸ¥ Base64 æ•°æ®æ˜¯å¦æœ‰æ•ˆ
                    return base64_data
        except:
            return None

    def is_base64_image(self, base64_data: str) -> bool:
        """
        æ£€æµ‹ Base64 æ•°æ®æ˜¯å¦ä¸ºæœ‰æ•ˆå›¾ç‰‡
        :param base64_data: Base64 ç¼–ç çš„å­—ç¬¦ä¸²
        :return: å¦‚æœæ˜¯å›¾ç‰‡è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
        """
        try:
            # è§£ç  Base64 æ•°æ®
            image_data = base64.b64decode(base64_data)
            # å°è¯•ç”¨ Pillow æ‰“å¼€å›¾ç‰‡
            image = Img.open(io.BytesIO(image_data))
            # å¦‚æœå›¾ç‰‡èƒ½æ­£ç¡®è¢«æ‰“å¼€ï¼Œå†æ£€æŸ¥æ ¼å¼æ˜¯å¦ä¸ºæ”¯æŒçš„å›¾ç‰‡æ ¼å¼
            image.verify()  # éªŒè¯å›¾ç‰‡
            return True  # Base64 æ˜¯æœ‰æ•ˆå›¾ç‰‡
        except Exception:
            return False  # å¦‚æœè§£æå¤±è´¥ï¼Œè¯´æ˜ä¸æ˜¯å›¾ç‰‡

    async def _search_calibre_web(self, query: str, limit: int = None):
        '''Call the Calibre-Web Catalog API to search for eBooks.'''
        calibre_web_url = self.config.get("calibre_web_url", "http://127.0.0.1:8083")
        search_url = f"{calibre_web_url}/opds/search/{query}"  # æ ¹æ®å®é™…è·¯å¾„æ„é€  API URL

        async with aiohttp.ClientSession() as session:
            async with session.get(search_url) as response:
                if response.status == 200:
                    content_type = response.headers.get("Content-Type", "")
                    if "application/atom+xml" in content_type:
                        data = await response.text()
                        return self._parse_opds_response(data, limit)  # è°ƒç”¨è§£ææ–¹æ³•
                    else:
                        logger.error(f"[Calibre-Web] Unexpected content type: {content_type}")
                        return None
                else:
                    logger.error(
                        f"[Calibre-Web] Error during search: Calibre-Web returned status code {response.status}")
                    return None

    def _parse_opds_response(self, xml_data: str, limit: int = None):
        '''Parse the opds search result XML data.'''
        calibre_web_url = self.config.get("calibre_web_url", "http://127.0.0.1:8083")

        # Remove illegal characters
        xml_data = re.sub(r'[^\x09\x0A\x0D\x20-\uD7FF\uE000-\uFFFD]', '', xml_data)
        # æ¶ˆé™¤å¤šä½™ç©ºæ ¼
        xml_data = re.sub(r'\s+', ' ', xml_data)

        try:
            root = ET.fromstring(xml_data)  # æŠŠ XML è½¬æ¢ä¸ºå…ƒç´ æ ‘
            namespace = {"default": "http://www.w3.org/2005/Atom"}  # å®šä¹‰å‘½åç©ºé—´
            entries = root.findall("default:entry", namespace)  # æŸ¥æ‰¾å‰20ä¸ª <entry> èŠ‚ç‚¹

            results = []
            for entry in entries:
                # æå–ç”µå­ä¹¦æ ‡é¢˜
                title_element = entry.find("default:title", namespace)
                title = title_element.text if title_element is not None else "æœªçŸ¥æ ‡é¢˜"

                # æå–ä½œè€…ï¼Œå¤šä½œè€…åœºæ™¯
                authors = []
                author_elements = entry.findall("default:author/default:name", namespace)
                for author in author_elements:
                    authors.append(author.text if author is not None else "æœªçŸ¥ä½œè€…")
                authors = ", ".join(authors) if authors else "æœªçŸ¥ä½œè€…"

                # æå–æè¿°ï¼ˆ<summary>ï¼‰
                summary_element = entry.find("default:summary", namespace)
                summary = summary_element.text if summary_element is not None else "æš‚æ— æè¿°"

                # æå–å‡ºç‰ˆæ—¥æœŸï¼ˆ<published>ï¼‰
                published_element = entry.find("default:published", namespace)
                #published_date = published_element.text if published_element is not None else "æœªçŸ¥å‡ºç‰ˆæ—¥æœŸ"
                if published_element is not None and published_element.text:
                    try:
                        # è§£ææ—¥æœŸå­—ç¬¦ä¸²ä¸º datetime å¯¹è±¡ï¼Œå¹¶æå–å¹´ä»½
                        year = datetime.fromisoformat(published_element.text).year
                    except ValueError:
                        year = "æœªçŸ¥å¹´ä»½"  # æ—¥æœŸè§£æå¤±è´¥æ—¶å¤„ç†
                else:
                    year = "æœªçŸ¥å¹´ä»½"

                # æå–è¯­è¨€ï¼ˆ<dcterms:language>ï¼‰ï¼Œéœ€æ³¨æ„ namespace
                lang_element = entry.find("default:dcterms:language", namespace)
                language = lang_element.text if lang_element is not None else "æœªçŸ¥è¯­è¨€"

                # æå–å‡ºç‰ˆç¤¾ä¿¡æ¯ï¼ˆ<publisher>ï¼‰
                publisher_element = entry.find("default:publisher/default:name", namespace)
                publisher = publisher_element.text if publisher_element is not None else "æœªçŸ¥å‡ºç‰ˆç¤¾"

                # æå–å›¾ä¹¦å°é¢é“¾æ¥ï¼ˆrel="http://opds-spec.org/image"ï¼‰
                cover_element = entry.find("default:link[@rel='http://opds-spec.org/image']", namespace)
                cover_suffix = cover_element.attrib.get("href", "") if cover_element is not None else ""
                if cover_suffix and re.match(r"^/opds/cover/\d+$", cover_suffix):
                    cover_link = urljoin(calibre_web_url, cover_suffix)
                else:
                    cover_link = ""

                # æå–å›¾ä¹¦ç¼©ç•¥å›¾é“¾æ¥ï¼ˆrel="http://opds-spec.org/image/thumbnail"ï¼‰
                thumbnail_element = entry.find("default:link[@rel='http://opds-spec.org/image/thumbnail']", namespace)
                thumbnail_suffix = thumbnail_element.attrib.get("href", "") if thumbnail_element is not None else ""
                if thumbnail_suffix and re.match(r"^/opds/cover/\d+$", thumbnail_suffix):
                    thumbnail_link = urljoin(calibre_web_url, thumbnail_suffix)
                else:
                    thumbnail_link = ""

                # æå–ä¸‹è½½é“¾æ¥åŠå…¶æ ¼å¼ï¼ˆrel="http://opds-spec.org/acquisition"ï¼‰
                acquisition_element = entry.find("default:link[@rel='http://opds-spec.org/acquisition']", namespace)
                if acquisition_element is not None:
                    download_suffix = acquisition_element.attrib.get("href", "") if acquisition_element is not None else ""
                    if download_suffix and re.match(r"^/opds/download/\d+/[\w]+/$", download_suffix):
                        download_link = urljoin(calibre_web_url, download_suffix)
                    else:
                        download_link = ""
                    file_type = acquisition_element.attrib.get("type", "æœªçŸ¥æ ¼å¼")
                    file_size = acquisition_element.attrib.get("length", "æœªçŸ¥å¤§å°")
                else:
                    download_link = ""
                    file_type = "æœªçŸ¥æ ¼å¼"
                    file_size = "æœªçŸ¥æ ¼å¼"

                # æ„å»ºç»“æœ
                results.append({
                    "title": title,
                    "authors": authors,
                    "summary": summary,
                    "year": year,
                    "publisher": publisher,
                    "language": language,
                    "cover_link": cover_link,
                    "thumbnail_link": thumbnail_link,
                    "download_link": download_link,
                    "file_type": file_type,
                    "file_size": file_size
                })

            return results[:limit]
        except ET.ParseError as e:
            logger.error(f"[Calibre-Web] Error parsing OPDS response: {e}")
            return None

    async def build_book_chain(self, item: dict) -> list:
        """
        æ„å»ºå¯¹åº”ä¹¦ç±æ¡ç›®çš„æ¶ˆæ¯é“¾ã€‚

        :param item: åŒ…å«ä¹¦ç±ä¿¡æ¯çš„å­—å…¸
        :return: ç”Ÿæˆçš„æ¶ˆæ¯é“¾åˆ—è¡¨
        """
        chain = [Plain(f"{item['title']}")]
        if item.get("cover_link") and await self.is_url_accessible(item.get("cover_link")):
            chain.append(Image.fromURL(item["cover_link"]))
        else:
            chain.append(Plain("\n"))
        chain.append(Plain(f"ä½œè€…: {item.get('authors', 'æœªçŸ¥')}\n"))
        chain.append(Plain(f"å¹´ä»½: {item.get('year', 'æœªçŸ¥')}\n"))
        chain.append(Plain(f"å‡ºç‰ˆç¤¾: {item.get('publisher', 'æœªçŸ¥')}\n"))
        description = item.get("summary", "")
        if isinstance(description, str) and description != "":
            description = description.strip()
            description = description[:150] + "..." if len(description) > 150 else description
        else:
            description = "æ— ç®€ä»‹"
        chain.append(Plain(f"ç®€ä»‹: {description}\n"))
        chain.append(Plain(f"é“¾æ¥(ç”¨äºä¸‹è½½): {item.get('download_link', 'æœªçŸ¥')}"))
        return chain

    async def _show_calibre_result(self, event: AstrMessageEvent, results: list, guidance: str = None):
        if not results:
            yield event.plain_result("[Calibre-Web] æœªæ‰¾åˆ°åŒ¹é…çš„ç”µå­ä¹¦ã€‚")
            return

        ns = Nodes([])
        if guidance:
            ns.nodes.append(Node(uin=event.get_self_id(), name="Calibre-Web", content=guidance))

        for item in results:
            chain = await self.build_book_chain(item)
            node = Node(
                uin=event.get_self_id(),
                name="Calibre-Web",
                content=chain
            )
            ns.nodes.append(node)

        yield event.chain_result([ns])

    def is_valid_calibre_book_url(self, book_url: str) -> bool:
        """æ£€æµ‹ç”µå­ä¹¦ä¸‹è½½é“¾æ¥æ ¼å¼æ˜¯å¦åˆæ³•"""
        if not book_url:
            return False  # URL ä¸èƒ½ä¸ºç©º

        # æ£€æµ‹æ˜¯å¦æ˜¯åˆæ³•çš„ URL (åŸºç¡€éªŒè¯)
        pattern = re.compile(r'^https?://.+/.+$')
        if not pattern.match(book_url):
            return False

        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³ç‰¹å®šçš„ç»“æ„ï¼Œä¾‹å¦‚åŒ…å« /opds/download/
        if "/opds/download/" not in book_url:
            return False

        return True

    @command_group("calibre")
    def calibre(self):
        pass

    @calibre.command("search")
    async def search_calibre(self, event: AstrMessageEvent, query: str, limit: str="20"):
        '''æœç´¢ calibre-web ç”µå­ä¹¦ç›®å½•'''
        if not self.config.get("enable_calibre", False):
            yield event.plain_result("[Calibre-Web] åŠŸèƒ½æœªå¯ç”¨ã€‚")
            return

        if not query:
            yield event.plain_result("[Calibre-Web] è¯·æä¾›ç”µå­ä¹¦å…³é”®è¯ä»¥è¿›è¡Œæœç´¢ã€‚")
            return

        limit = int(limit) if limit.isdigit() else 20
        if not (1 <= limit <= 50):  # Validate limit
            yield event.plain_result("[Calibre-Web] è¯·ç¡®è®¤æœç´¢è¿”å›ç»“æœæ•°é‡åœ¨ 1-50 ä¹‹é—´ã€‚")
            return

        try:
            logger.info(f"[Calibre-Web] Received books search query: {query}, limit: {limit}")
            results = await self._search_calibre_web(quote_plus(query), limit)  # è°ƒç”¨æœç´¢æ–¹æ³•
            if not results or len(results) == 0:
                yield event.plain_result("[Calibre-Web] æœªæ‰¾åˆ°åŒ¹é…çš„ç”µå­ä¹¦ã€‚")
            else:
                async for result in self._show_calibre_result(event, results):
                    yield result
        except Exception as e:
            logger.error(f"[Calibre-Web] æœç´¢å¤±è´¥: {e}")
            yield event.plain_result("[Calibre-Web] æœç´¢ç”µå­ä¹¦æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚")

    @calibre.command("download")
    async def download_calibre(self, event: AstrMessageEvent, book_url: str = None):
        '''ä¸‹è½½ calibre-web ç”µå­ä¹¦'''
        if not self.config.get("enable_calibre", False):
            yield event.plain_result("[Calibre-Web] åŠŸèƒ½æœªå¯ç”¨ã€‚")
            return

        if not self.is_valid_calibre_book_url(book_url):
            yield event.plain_result("[Calibre-Web] è¯·æä¾›æœ‰æ•ˆçš„ç”µå­ä¹¦é“¾æ¥ã€‚")
            return

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(book_url) as response:
                    if response.status == 200:
                        # ä» Content-Disposition æå–æ–‡ä»¶å
                        content_disposition = response.headers.get("Content-Disposition")
                        book_name = None

                        if content_disposition:
                            # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰ filename*= æ¡ç›®
                            book_name_match = re.search(r'filename\*=(?:UTF-8\'\')?([^;]+)', content_disposition)
                            if book_name_match:
                                book_name = book_name_match.group(1)
                                book_name = unquote(book_name)  # è§£ç  URL ç¼–ç çš„æ–‡ä»¶å
                            else:
                                # å¦‚æœæ²¡æœ‰ filename*ï¼Œåˆ™æŸ¥æ‰¾æ™®é€šçš„ filename
                                book_name_match = re.search(r'filename=["\']?([^;\']+)["\']?', content_disposition)
                                if book_name:
                                    book_name = book_name_match.group(1)

                        # å¦‚æœæœªè·å–åˆ°æ–‡ä»¶åï¼Œä½¿ç”¨é»˜è®¤å€¼
                        if not book_name or book_name.strip() == "":
                            logger.error(f"[Calibre-Web] æ— æ³•æå–ä¹¦åï¼Œç”µå­ä¹¦åœ°å€: {book_url}")
                            yield event.plain_result("[Calibre-Web] æ— æ³•æå–ä¹¦åï¼Œå–æ¶ˆå‘é€ç”µå­ä¹¦ã€‚")
                            return 
                            
                        # å‘é€æ–‡ä»¶åˆ°ç”¨æˆ·
                        file = File(name=book_name, file=book_url)
                        yield event.chain_result([file])
                    else:
                        yield event.plain_result(f"[Calibre-Web] æ— æ³•ä¸‹è½½ç”µå­ä¹¦ï¼ŒçŠ¶æ€ç : {response.status}")
        except Exception as e:
            logger.error(f"[Calibre-Web] ä¸‹è½½å¤±è´¥: {e}")
            yield event.plain_result("[Calibre-Web] ä¸‹è½½ç”µå­ä¹¦æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚")

    @calibre.command("recommend")
    async def recommend_calibre(self, event: AstrMessageEvent, n: int):
        '''éšæœºæ¨è n æœ¬ç”µå­ä¹¦'''
        if not self.config.get("enable_calibre", False):
            yield event.plain_result("[Calibre-Web] åŠŸèƒ½æœªå¯ç”¨ã€‚")
            return

        try:
            # è°ƒç”¨ Calibre-Web æœç´¢æ¥å£ï¼Œé»˜è®¤æœç´¢æ‰€æœ‰ç”µå­ä¹¦
            query = "*"  # ç©ºæŸ¥è¯¢ï¼Œå¯ä»¥è°ƒå‡ºå®Œæ•´ä¹¦ç›®
            results = await self._search_calibre_web(query)

            # æ£€æŸ¥æ˜¯å¦æœ‰ç”µå­ä¹¦å¯ä¾›æ¨è
            if not results:
                yield event.plain_result("[Calibre-Web] æœªæ‰¾åˆ°å¯æ¨èçš„ç”µå­ä¹¦ã€‚")
                return

            # é™åˆ¶æ¨èæ•°é‡ï¼Œé˜²æ­¢è¶…å‡ºå®é™…ç”µå­ä¹¦æ•°é‡
            if n > len(results):
                n = len(results)

            # éšæœºé€‰æ‹© n æœ¬ç”µå­ä¹¦
            recommended_books = random.sample(results, n)

            # æ˜¾ç¤ºæ¨èç”µå­ä¹¦
            guidance = f"å¦‚ä¸‹æ˜¯éšæœºæ¨èçš„ {n} æœ¬ç”µå­ä¹¦"
            async for result in self._show_calibre_result(event, recommended_books, guidance):
                yield result

        except Exception as e:
            logger.error(f"[Calibre-Web] æ¨èç”µå­ä¹¦æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            yield event.plain_result("[Calibre-Web] æ¨èç”µå­ä¹¦æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚")

    # @llm_tool("search_calibre_books")
    async def search_calibre_books(self, event: AstrMessageEvent, query: str):
        """Search books by keywords or title through Calibre-Web.
        When to use:
            Use this method to search for books in the Calibre-Web catalog when user knows the title or keyword.
            This method cannot be used for downloading books and should only be used for searching purposes.

        Args:
            query (string): The search keyword or title to find books in the Calibre-Web catalog.
        """
        async for result in self.search_calibre(event, query):
            yield result

    # @llm_tool("download_calibre_book")
    async def download_calibre_book(self, event: AstrMessageEvent, book_url: str):
        """Download a book by a precise name or URL through Calibre-Web.
        When to use:
            Use this method to download a specific book by its name or when a direct download link is available.
    
        Args:
            book_url (string): The book name (exact match) or the URL of the book link.

        """
        async for result in self.download_calibre(event, book_url):
            yield result

    @llm_tool("recommend_books")
    async def recommend_calibre_books(self, event: AstrMessageEvent, n: str = "5"):
        """Randomly recommend n books.
        When to use:
            Use this method to get a random selection of books when users are unsure what to read.
    
        Args:
            n (string): Number of books to recommend (default is 5).
        """
        async for result in self.recommend_calibre(event, int(n)):
            yield result
            
    async def get_liber3_book_details(self, book_ids: list) -> Optional[dict]:
        """é€šè¿‡ç”µå­ä¹¦ ID è·å–è¯¦ç»†ä¿¡æ¯"""
        detail_url = "https://lgate.glitternode.ru/v1/book"
        headers = {"Content-Type": "application/json"}
        payload = {"book_ids": book_ids}

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(detail_url, headers=headers, json=payload, proxy=self.proxy) as response:
                    if response.status == 200:
                        data = await response.json()
                        return data.get("data", {}).get("book", {})
                    else:
                        logger.error(f"[Liber3] Error during detail request: Status code {response.status}")
                        return None
        except aiohttp.ClientError as e:
            logger.error(f"[Liber3] HTTP client error: {e}")
        except Exception as e:
            logger.error(f"[Liber3] å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")

        return None
    
    async def search_liber3_books_with_details(self, word: str, limit: int = 50) -> Optional[dict]:
        """æœç´¢ç”µå­ä¹¦å¹¶è·å–å‰ limit æœ¬ç”µå­ä¹¦çš„è¯¦ç»†ä¿¡æ¯"""
        search_url = "https://lgate.glitternode.ru/v1/searchV2"
        headers = {"Content-Type": "application/json"}
        payload = {
            "address": "",
            "word": word
        }

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(search_url, headers=headers, json=payload, proxy=self.proxy) as response:
                    if response.status == 200:
                        data = await response.json()

                        # è·å–ç”µå­ä¹¦ ID åˆ—è¡¨
                        book_data = data["data"].get("book", [])
                        if not book_data:
                            logger.info("[Liber3] æœªæ‰¾åˆ°åŒ¹é…çš„ç”µå­ä¹¦ã€‚")
                            return None

                        book_ids = [item.get("id") for item in book_data[:limit]]
                        if not book_ids:
                            logger.info("[Liber3] æœªèƒ½æå–ç”µå­ä¹¦ IDã€‚")
                            return None

                        # è°ƒç”¨è¯¦ç»†ä¿¡æ¯ API
                        detailed_books = await self.get_liber3_book_details(book_ids)
                        if not detailed_books:
                            logger.info("[Liber3] æœªè·å–ç”µå­ä¹¦è¯¦ç»†ä¿¡æ¯ã€‚")
                            return None

                        # è¿”å›åŒ…å«æœç´¢ç»“æœåŠè¯¦ç»†ä¿¡æ¯çš„æ•°æ®
                        return {
                            "search_results": book_data[:limit],
                            "detailed_books": detailed_books
                        }

                    else:
                        logger.error(f"[Liber3] è¯·æ±‚ç”µå­ä¹¦æœç´¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None
        except aiohttp.ClientError as e:
            logger.error(f"[Liber3] HTTP å®¢æˆ·ç«¯é”™è¯¯: {e}")
        except Exception as e:
            logger.error(f"[Liber3] å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")

        return None

    def is_valid_liber3_book_id(self, book_id: str) -> bool:
        """æ£€æµ‹ Liber3 çš„ book_id æ˜¯å¦æœ‰æ•ˆ"""
        if not book_id:
            return False  # ä¸èƒ½ä¸ºç©º

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼éªŒè¯æ˜¯å¦æ˜¯ 32 ä½å¤§å†™åå…­è¿›åˆ¶å­—ç¬¦ä¸²
        pattern = re.compile(r'^[a-fA-F0-9]{32}$')
        return bool(pattern.match(book_id))

    @command_group("liber3")
    def liber3(self):
        pass

    @liber3.command("search")
    async def search_liber3(self, event: AstrMessageEvent, query: str = None, limit: str="20"):
        """æœç´¢ç”µå­ä¹¦å¹¶è¾“å‡ºè¯¦ç»†ä¿¡æ¯"""
        if not self.config.get("enable_liber3", False):
            yield event.plain_result("[Liber3] åŠŸèƒ½æœªå¯ç”¨ã€‚")
            return

        if not query:
            yield event.plain_result("[Liber3] è¯·æä¾›ç”µå­ä¹¦å…³é”®è¯ä»¥è¿›è¡Œæœç´¢ã€‚")
            return

        limit = int(limit) if limit.isdigit() else 20
        if not (1 <= limit <= 50):  # Validate limit
            yield event.plain_result("[Liber3] è¯·ç¡®è®¤æœç´¢è¿”å›ç»“æœæ•°é‡åœ¨ 1-50 ä¹‹é—´ã€‚")
            return

        logger.info(f"[Liber3] Received books search query: {query}, limit: {limit}")
        results = await self.search_liber3_books_with_details(query, limit)

        if not results:
            yield event.plain_result("[Liber3] æœªæ‰¾åˆ°åŒ¹é…çš„ç”µå­ä¹¦ã€‚")
            return

        # è¾“å‡ºæœç´¢ç»“æœå’Œè¯¦ç»†ä¿¡æ¯
        search_results = results.get("search_results", [])
        detailed_books = results.get("detailed_books", {})

        ns = Nodes([])

        for book in search_results:
            book_id = book.get("id")
            detail = detailed_books.get(book_id, {}).get("book", {})

            chain = [
                Plain(f"ä¹¦å: {book.get('title', 'æœªçŸ¥')}\n"),
                Plain(f"ä½œè€…: {book.get('author', 'æœªçŸ¥')}\n"),
                Plain(f"å¹´ä»½: {detail.get('year', 'æœªçŸ¥')}\n"),
                Plain(f"å‡ºç‰ˆç¤¾: {detail.get('publisher', 'æœªçŸ¥')}\n"),
                Plain(f"è¯­è¨€: {detail.get('language', 'æœªçŸ¥')}\n"),
                Plain(f"æ–‡ä»¶å¤§å°: {detail.get('filesize', 'æœªçŸ¥')}\n"),
                Plain(f"æ–‡ä»¶ç±»å‹: {detail.get('extension', 'æœªçŸ¥')}\n"),
                Plain(f"ID(ç”¨äºä¸‹è½½): {book_id}"),
            ]

            node = Node(
                uin=event.get_self_id(),
                name="Liber3",
                content=chain
            )
            ns.nodes.append(node)

        yield event.chain_result([ns])

    @liber3.command("download")
    async def download_liber3(self, event: AstrMessageEvent, book_id: str = None):
        if not self.config.get("enable_liber3", False):
            yield event.plain_result("[Liber3] åŠŸèƒ½æœªå¯ç”¨ã€‚")
            return

        if not self.is_valid_liber3_book_id(book_id):
            yield event.plain_result("[Liber3] è¯·æä¾›æœ‰æ•ˆçš„ç”µå­ä¹¦ IDã€‚")
            return

        # è·å–è¯¦ç»†çš„ç”µå­ä¹¦ä¿¡æ¯
        book_details = await self.get_liber3_book_details([book_id])
        if not book_details or book_id not in book_details:
            yield event.plain_result("[Liber3] æ— æ³•è·å–ç”µå­ä¹¦å…ƒä¿¡æ¯ï¼Œè¯·æ£€æŸ¥ç”µå­ä¹¦ ID æ˜¯å¦æ­£ç¡®ã€‚")
            return

        # æå–ç”µå­ä¹¦ä¿¡æ¯
        book_info = book_details[book_id].get("book", {})
        book_name = book_info.get("title", "unknown_book").replace(" ", "_")
        extension = book_info.get("extension", "unknown_extension")
        ipfs_cid = book_info.get("ipfs_cid", "")

        if not ipfs_cid or not extension:
            yield event.plain_result("[Liber3] ç”µå­ä¹¦ä¿¡æ¯ä¸è¶³ï¼Œæ— æ³•å®Œæˆä¸‹è½½ã€‚")
            return

        # æ„é€ ä¸‹è½½é“¾æ¥
        ebook_url = f"https://gateway-ipfs.st/ipfs/{ipfs_cid}?filename={book_name}.{extension}"

        # ä½¿ç”¨ File å¯¹è±¡ï¼Œé€šè¿‡ chain_result ä¸‹è½½
        file = File(name=f"{book_name}.{extension}", file=ebook_url)
        yield event.chain_result([file])

    # @llm_tool("search_liber3_books")
    async def search_liber3_books(self, event: AstrMessageEvent, query: str):
        """Search for books using Liber3 API and return a detailed result list.

        When to use:
            Invoke this tool to locate books based on keywords or titles from Liber3's library.

        Args:
            query (string): The keyword or title to search for books.
        """
        async for result in self.search_liber3(event, query):
            yield result

    # @llm_tool("download_liber3_book")
    async def download_liber3_book(self, event: AstrMessageEvent, book_id: str):
        """Download a book using Liber3's API via its unique ID.

        When to use:
            This tool allows you to retrieve a Liber3 book using the unique ID and download it.

        Args:
            book_id (string): A valid Liber3 book ID required to download a book.
        """
        async for result in self.download_liber3(event, book_id):
            yield result

    async def _search_archive_books(self, query: str, limit: int = 20):
        """Search for eBooks through the Archive API and filter files in PDF or EPUB formats.
            Args:
                query (str): Search keyword for titles
                limit (int): Maximum number of results to return
            Returns:
                list: A list containing book information and download links that meet the criteria
        """
        base_search_url = "https://archive.org/advancedsearch.php"
        base_metadata_url = "https://archive.org/metadata/"
        formats = ("pdf", "epub")  # æ”¯æŒçš„ç”µå­ä¹¦æ ¼å¼

        params = {
            "q": f'title:"{query}" mediatype:texts',  # æ ¹æ®æ ‡é¢˜æœç´¢
            "fl[]": "identifier,title",  # è¿”å› identifier å’Œ title å­—æ®µ
            "sort[]": "downloads desc",  # æŒ‰ä¸‹è½½é‡æ’åº
            "rows": limit+10,  # æœ€å¤§ç»“æœæ•°é‡
            "page": 1,
            "output": "json"  # è¿”å›æ ¼å¼ä¸º JSON
        }

        async with aiohttp.ClientSession() as session:
            # 1. è°ƒç”¨ Archive æœç´¢ API
            response = await session.get(base_search_url, params=params, proxy=self.proxy)
            if response.status != 200:
                logger.error(
                    f"[Archive] Error during search: Archive API returned status code {response.status}")
                return []

            result_data = await response.json()
            docs = result_data.get("response", {}).get("docs", [])
            if not docs:
                logger.info("[Archive] æœªæ‰¾åˆ°åŒ¹é…çš„ç”µå­ä¹¦ã€‚")
                return []

            # 2. æ ¹æ® identifier æå–å…ƒæ•°æ®
            tasks = [
                self._fetch_metadata(session, base_metadata_url + doc["identifier"], formats) for doc in docs
            ]
            metadata_results = await asyncio.gather(*tasks)

            # 3. ç­›é€‰æœ‰æ•ˆç»“æœå¹¶è¿”å›
            books = [
                {
                    "title": doc.get("title"),
                    "cover": metadata.get("cover"),
                    "authors": metadata.get("authors"),
                    "language": metadata.get("language"),
                    "year": metadata.get("year"),
                    "publisher": metadata.get("publisher"),
                    "download_url": metadata.get("download_url"),
                    "description": metadata.get("description")
                }
                for doc, metadata in zip(docs, metadata_results) if metadata
            ][:limit]
            return books

    async def _fetch_metadata(self, session: aiohttp.ClientSession, url: str, formats: tuple) -> dict:
        """
            Retrieve specific eBook formats from the Metadata API and extract covers and descriptions.
            Args:
                session (aiohttp.ClientSession): aiohttp session
                url (str): URL of the Metadata API
                formats (tuple): Required formats (e.g., PDF, EPUB)
            Returns:
                dict: A dictionary with download links, file type, cover, and description
        """
        try:
            response = await session.get(url, proxy=self.proxy)
            if response.status != 200:
                logger.error(f"[Archive] Error retrieving Metadata: Status code {response.status}")
                return {}

            book_detail = await response.json()

            identifier = book_detail.get("metadata", {}).get("identifier", None)
            if not identifier:
                return {}
            files = book_detail.get("files", [])
            description = book_detail.get("metadata", {}).get("description", "æ— ç®€ä»‹")
            authors = book_detail.get("metadata", {}).get("creator", "æœªçŸ¥")
            language = book_detail.get("metadata", {}).get("language", "æœªçŸ¥")
            year = book_detail.get("metadata", {}).get("publicdate", "æœªçŸ¥")[:4] if book_detail.get("metadata", {}).get(
                "publicdate", "æœªçŸ¥") != "æœªçŸ¥" else "æœªçŸ¥"
            publisher = book_detail.get("metadata", {}).get("publisher", "æœªçŸ¥")

            # åˆ¤æ–­å¹¶è§£æç®€ä»‹
            if isinstance(description, str):
                if self._is_html(description):
                    description = self._parse_html_to_text(description)
                else:
                    description = description.strip()
                description = description[:150] + "..." if len(description) > 150 else description
            else:
                description = "æ— ç®€ä»‹"

            # æå–ç‰¹å®šæ ¼å¼æ–‡ä»¶ï¼ˆå¦‚ PDF å’Œ EPUBï¼‰
            for file in files:
                if any(file.get("name", "").lower().endswith(fmt) for fmt in formats):
                    return {
                        "cover": f"https://archive.org/services/img/{identifier}",
                        "authors": authors,
                        "year": year,
                        "publisher": publisher,
                        "language": language,
                        "description": description,
                        "download_url": f"https://archive.org/download/{identifier}/{file['name']}",
                    }

        except Exception as e:
            logger.error(f"[Archive] è·å– Metadata æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}

    def _is_html(self, content):
        """Determine whether a string is in HTML format."""
        if not isinstance(content, str):
            return False
        return bool(re.search(r'<[^>]+>', content))

    def _parse_html_to_text(self, html_content):
        """Parse HTML content into plain text."""
        soup = BeautifulSoup(html_content, "html.parser")
        return soup.get_text().strip()

    def is_valid_archive_book_url(self, book_url: str) -> bool:
        """æ£€æµ‹ archive.org ä¸‹è½½é“¾æ¥æ ¼å¼æ˜¯å¦åˆæ³•"""
        if not book_url:
            return False  # URL ä¸èƒ½ä¸ºç©º

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼éªŒè¯é“¾æ¥æ ¼å¼æ˜¯å¦åˆæ³•
        pattern = re.compile(
            r'^https://archive\.org/download/[^/]+/[^/]+$'
        )

        return bool(pattern.match(book_url))

    @command_group("archive")
    def archive(self):
        pass

    @archive.command("search")
    async def search_archive(self, event: AstrMessageEvent, query: str = None, limit: str = "20"):
        """
            Search for eBooks using the Archive platform, filtering for supported formats.
            Args:
                query (str): The book title or keywords to search for (required).
                limit (str): The result limit, default is 20.
        """
        if not self.config.get("enable_archive", False):
            yield event.plain_result("[Archive] åŠŸèƒ½æœªå¯ç”¨ã€‚")
            return

        if not query:
            yield event.plain_result("[Archive] è¯·æä¾›ç”µå­ä¹¦å…³é”®è¯ä»¥è¿›è¡Œæœç´¢ã€‚")
            return
        
        limit = int(limit) if limit.isdigit() else 20
        if not (1 <= limit <= 50):  # Validate limit
            yield event.plain_result("[Archive] è¯·ç¡®è®¤æœç´¢è¿”å›ç»“æœæ•°é‡åœ¨ 1-50 ä¹‹é—´ã€‚")
            return
        try:
            logger.info(f"[Archive] Received books search query: {query}, limit: {limit}")
            results = await self._search_archive_books(query, limit)

            if not results:
                yield event.plain_result("[Archive] æœªæ‰¾åˆ°åŒ¹é…çš„ç”µå­ä¹¦ã€‚")
                return

            # è¿”å›ç»“æœåˆ°ç”¨æˆ·
            ns = Nodes([])
            for book in results:
                chain = [Plain(f"{book.get('title', 'æœªçŸ¥')}")]
                if book.get("cover") and await self.is_url_accessible(book.get("cover")):
                    base64_image = await self.download_and_convert_to_base64(book.get("cover"))
                    if base64_image:
                        chain.append(Image.fromBase64(base64_image))
                    else:
                        chain.append(Plain("\n"))
                else:
                    chain.append(Plain("\n"))
                chain.append(Plain(f"ä½œè€…: {book.get('authors', 'æœªçŸ¥')}\n"))
                chain.append(Plain(f"å¹´ä»½: {book.get('year', 'æœªçŸ¥')}\n"))
                chain.append(Plain(f"å‡ºç‰ˆç¤¾: {book.get('publisher', 'æœªçŸ¥')}\n"))
                chain.append(Plain(f"è¯­è¨€: {book.get('language', 'æœªçŸ¥')}\n"))
                chain.append(Plain(f"ç®€ä»‹: {book.get('description', 'æ— ç®€ä»‹')}\n"))
                chain.append(Plain(f"é“¾æ¥(ç”¨äºä¸‹è½½): {book.get('download_url', 'æœªçŸ¥')}"))

                node = Node(uin=event.get_self_id(), name="Archive", content=chain)
                ns.nodes.append(node)

            yield event.chain_result([ns])

        except Exception as e:
            logger.error(f"[Archive] Error processing Archive search request: {e}")
            yield event.plain_result("[Archive] æœç´¢ç”µå­ä¹¦æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚")

    @archive.command("download")
    async def download_archive(self, event: AstrMessageEvent, book_url: str = None):
        """Download an eBook from the Archive platform using a provided link.
            Args:
                book_url (str): The download URL of the eBook.
        """
        if not self.config.get("enable_archive", False):
            yield event.plain_result("[Archive] åŠŸèƒ½æœªå¯ç”¨ã€‚")
            return

        if not self.is_valid_archive_book_url(book_url):
            yield event.plain_result("[Archive] è¯·æä¾›æœ‰æ•ˆçš„ä¸‹è½½é“¾æ¥ã€‚")
            return

        try:
            async with aiohttp.ClientSession() as session:
                # å‘å‡º GET è¯·æ±‚å¹¶è·Ÿéšè·³è½¬
                async with session.get(book_url, allow_redirects=True, proxy=self.proxy) as response:
                    if response.status == 200:
                        ebook_url = str(response.url)
                        logger.debug(f"[Archive] è·³è½¬åçš„ä¸‹è½½åœ°å€: {ebook_url}")

                        # ä» Content-Disposition æå–æ–‡ä»¶å
                        content_disposition = response.headers.get("Content-Disposition", "")
                        book_name = None

                        # æå–æ–‡ä»¶å
                        if content_disposition:
                            book_name_match = re.search(r'filename\*=(?:UTF-8\'\')?([^;]+)', content_disposition)
                            if book_name_match:
                                book_name = unquote(book_name_match.group(1))
                            else:
                                book_name_match = re.search(r'filename=["\']?([^;\']+)["\']?', content_disposition)
                                if book_name_match:
                                    book_name = book_name_match.group(1)

                        # å¦‚æœæœªæå–åˆ°æ–‡ä»¶åï¼Œå°è¯•ä» URL æå–
                        if not book_name or book_name.strip() == "":
                            parsed_url = urlparse(ebook_url)
                            book_name = os.path.basename(parsed_url.path) or "unknown_book"

                        # æ„é€ ä¸´æ—¶æ–‡ä»¶è·¯å¾„
                        temp_file_path = os.path.join(self.TEMP_PATH, book_name)

                        # ä¿å­˜ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°
                        async with aiofiles.open(temp_file_path, "wb") as temp_file:
                            await temp_file.write(await response.read())

                        # æ‰“å°æ—¥å¿—ç¡®è®¤ä¿å­˜æˆåŠŸ
                        logger.info(f"[Archive] æ–‡ä»¶å·²ä¸‹è½½å¹¶ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•ï¼š{temp_file_path}")

                        # ç›´æ¥ä¼ é€’æœ¬åœ°æ–‡ä»¶è·¯å¾„
                        file = File(name=book_name, file=temp_file_path)
                        yield event.chain_result([file])
                        os.remove(temp_file_path)

                        # file = File(name=book_name, file=ebook_url)
                        # yield event.chain_result([file])
                    else:
                        yield event.plain_result(f"[Archive] æ— æ³•ä¸‹è½½ç”µå­ä¹¦ï¼ŒçŠ¶æ€ç : {response.status}")
        except Exception as e:
            logger.error(f"[Archive] ä¸‹è½½å¤±è´¥: {e}")
            yield event.plain_result(f"[Archive] ä¸‹è½½ç”µå­ä¹¦æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚")

    # @llm_tool("search_archive_books")
    async def search_archive_books(self, event: AstrMessageEvent, query: str):
        """Search for eBooks using the Archive API.
    
        When to use:
            Utilize this method to search books available in supported formats (such as PDF or EPUB) on the Archive API platform.
    
        Args:
            query (string): The keywords or title to perform the search.
        """
        async for result in self.search_archive(event, query):
            yield result

    # @llm_tool("download_archive_book")
    async def download_archive_book(self, event: AstrMessageEvent, download_url: str):
        """Download an eBook from the Archive API using its download URL.
    
        When to use:
            Use this method to download a specific book from the Archive platform using the book's provided download link.
    
        Args:
            download_url (string): A valid and supported Archive book download URL.
        """
        async for result in self.download_archive(event, download_url):
            yield result

    def is_valid_zlib_book_id(self, book_id: str) -> bool:
        """æ£€æµ‹ zlib ID æ˜¯å¦ä¸ºçº¯æ•°å­—"""
        if not book_id:
            return False
        return book_id.isdigit()

    def is_valid_zlib_book_hash(self, hash: str) -> bool:
        """æ£€æµ‹ zlib Hash æ˜¯å¦ä¸º 6 ä½åå…­è¿›åˆ¶"""
        if not hash:
            return False
        pattern = re.compile(r'^[a-f0-9]{6}$', re.IGNORECASE)  # å¿½ç•¥å¤§å°å†™
        return bool(pattern.match(hash))

    @command_group("zlib")
    def zlib(self):
        pass

    @zlib.command("search")
    async def search_zlib(self, event: AstrMessageEvent, query: str = None, limit: str = "20"):
        """æœç´¢ Zlibrary ç”µå­ä¹¦å¹¶è¾“å‡ºè¯¦ç»†ä¿¡æ¯"""
        if not self.config.get("enable_zlib", False):
            yield event.plain_result("[Z-Library] åŠŸèƒ½æœªå¯ç”¨ã€‚")
            return

        if not query:
            yield event.plain_result("[Z-Library] è¯·æä¾›ç”µå­ä¹¦å…³é”®è¯ä»¥è¿›è¡Œæœç´¢ã€‚")
            return

        try:
            limit = int(limit) if limit.isdigit() else 20
            if not (1 <= limit <= 50):  # Validate limit
                yield event.plain_result("[Z-Library] è¯·ç¡®è®¤æœç´¢è¿”å›ç»“æœæ•°é‡åœ¨ 1-50 ä¹‹é—´ã€‚")
                return

            logger.info(f"[Z-Library] Received books search query: {query}, limit: {limit}")

            if not self.zlibrary:
                self.zlibrary = Zlibrary(email=self.config["zlib_email"], password=self.config["zlib_password"])

            # è°ƒç”¨ Zlibrary çš„ search æ–¹æ³•è¿›è¡Œæœç´¢
            results = self.zlibrary.search(message=query, limit=limit)

            if not results or not results.get("books"):
                yield event.plain_result("[Z-Library] æœªæ‰¾åˆ°åŒ¹é…çš„ç”µå­ä¹¦ã€‚")
                return

            # å¤„ç†æœç´¢ç»“æœ
            books = results.get("books", [])
            ns = Nodes([])

            for book in books:
                chain = [Plain(f"{book.get('title', 'æœªçŸ¥')}")]
                if book.get("cover") and await self.is_url_accessible(book.get("cover")):
                    base64_image = await self.download_and_convert_to_base64(book.get("cover"))
                    if base64_image:
                        chain.append(Image.fromBase64(base64_image))
                    else:
                        chain.append(Plain("\n"))
                else:
                    chain.append(Plain("\n"))
                chain.append(Plain(f"ä½œè€…: {book.get('author', 'æœªçŸ¥')}\n"))
                chain.append(Plain(f"å¹´ä»½: {book.get('year', 'æœªçŸ¥')}\n"))
                publisher = book.get("publisher", None)
                if not publisher or publisher == "None":
                    publisher = "æœªçŸ¥"
                chain.append(Plain(f"å‡ºç‰ˆç¤¾: {publisher}\n"))
                chain.append(Plain(f"è¯­è¨€: {book.get('language', 'æœªçŸ¥')}\n"))
                description = book.get("description", "æ— ç®€ä»‹")
                if isinstance(description, str) and description != "":
                    description = description.strip()
                    description = description[:150] + "..." if len(description) > 150 else description
                else:
                    description = "æ— ç®€ä»‹"
                chain.append(Plain(f"ç®€ä»‹: {description}\n"))
                chain.append(Plain(f"ID(ç”¨äºä¸‹è½½): {book.get('id')}\n"))
                chain.append(Plain(f"Hash(ç”¨äºä¸‹è½½): {book.get('hash')}"))

                node = Node(
                    uin=event.get_self_id(),
                    name="Z-Library",
                    content=chain,
                )
                ns.nodes.append(node)

            yield event.chain_result([ns])

        except Exception as e:
            logger.error(f"[Z-Library] Error during book search: {e}")
            yield event.plain_result("[Z-Library] æœç´¢ç”µå­ä¹¦æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚")

    @zlib.command("download")
    async def download_zlib(self, event: AstrMessageEvent, book_id: str = None, book_hash: str = None):
        """ä¸‹è½½ Z-Library ç”µå­ä¹¦"""
        if not self.config.get("enable_zlib", False):
            yield event.plain_result("[Z-Library] åŠŸèƒ½æœªå¯ç”¨ã€‚")
            return

        if not self.is_valid_zlib_book_id(book_id) or not self.is_valid_zlib_book_hash(book_hash):
            yield event.plain_result("è¯·ä½¿ç”¨ /zlib download <id> <hash> ä¸‹è½½ã€‚")
            return

        try:
            if not self.zlibrary:
                self.zlibrary = Zlibrary(email=self.config["zlib_email"], password=self.config["zlib_password"])

            # è·å–ç”µå­ä¹¦è¯¦æƒ…ï¼Œç¡®ä¿ ID åˆæ³•
            book_details = self.zlibrary.getBookInfo(book_id, hashid=book_hash)
            if not book_details:
                yield event.plain_result("[Z-Library] æ— æ³•è·å–ç”µå­ä¹¦è¯¦æƒ…ï¼Œè¯·æ£€æŸ¥ç”µå­ä¹¦ ID æ˜¯å¦æ­£ç¡®ã€‚")
                return

            # ä¸‹è½½ç”µå­ä¹¦
            downloaded_book = self.zlibrary.downloadBook({"id": book_id, "hash": book_hash})
            if downloaded_book:
                book_name, book_content = downloaded_book
                # æ„é€ ä¸´æ—¶æ–‡ä»¶è·¯å¾„
                temp_file_path = os.path.join(self.TEMP_PATH, book_name)

                # ä¿å­˜ç”µå­ä¹¦æ–‡ä»¶
                with open(temp_file_path, "wb") as file:
                    file.write(book_content)

                # æ‰“å°æ—¥å¿—ç¡®è®¤ä¿å­˜æˆåŠŸ
                logger.debug(f"[Z-Library] æ–‡ä»¶å·²ä¸‹è½½å¹¶ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•ï¼š{temp_file_path}")

                # æé†’ç”¨æˆ·ä¸‹è½½å®Œæˆ
                file = File(name=book_name, file=str(temp_file_path))
                yield event.chain_result([file])
                os.remove(temp_file_path)
            else:
                yield event.plain_result("[Z-Library] ä¸‹è½½ç”µå­ä¹¦æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚")

        except Exception as e:
            logger.error(f"[Z-Library] Error during book download: {e}")
            yield event.plain_result("[Z-Library] ä¸‹è½½ç”µå­ä¹¦æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚")

    # @llm_tool("search_zlib_books")
    async def search_zlib_books(self, event: AstrMessageEvent, query: str):
        """Search Zlibrary for books using given keywords.

        When to use:
            Use this method to locate books by keywords or title in Z-Library's database.

        Args:
            query (string): The search term to perform the lookup.
        """
        async for result in self.search_zlib(event, query):
            yield result

    # @llm_tool("download_zlib_book")
    async def download_zlib_book(self, event: AstrMessageEvent, book_id: str, book_hash: str):
        """Download a book from Z-Library using its book ID and hash.
    
        When to use:
            Use this method for downloading books from Zlibrary with the provided ID and hash.
    
        Args:
            book_id (string): The unique identifier for the book.
            book_hash (string): Hash value required to authorize and retrieve the download.
        """
        async for result in self.download_zlib(event, book_id, book_hash):
            yield result
    
    @command_group("ebooks")
    def ebooks(self):
        pass
    
    @ebooks.command("help")
    async def show_help(self, event: AstrMessageEvent):
        '''æ˜¾ç¤º Calibre-Web æ’ä»¶å¸®åŠ©ä¿¡æ¯'''
        help_msg = [
            "ğŸ“š **ebooks æ’ä»¶ä½¿ç”¨æŒ‡å—**",
            "",
            "æ”¯æŒé€šè¿‡å¤šå¹³å°ï¼ˆCalibre-Webã€Liber3ã€Z-Libraryã€Archive.orgï¼‰æœç´¢ã€ä¸‹è½½ç”µå­ä¹¦ã€‚",
            "",
            "---",
            "ğŸ”§ **å‘½ä»¤åˆ—è¡¨**:",
            "",
            "- **Calibre-Web**:",
            "  - `/calibre search <å…³é”®è¯> [æ•°é‡]`ï¼šæœç´¢ Calibre-Web ä¸­çš„ç”µå­ä¹¦ã€‚ä¾‹å¦‚ï¼š`/calibre search Python 20`ã€‚",
            "  - `/calibre download <ä¸‹è½½é“¾æ¥/ä¹¦å>`ï¼šé€šè¿‡ Calibre-Web ä¸‹è½½ç”µå­ä¹¦ã€‚ä¾‹å¦‚ï¼š`/calibre download <URL>`ã€‚",
            "  - `/calibre recommend <æ•°é‡>`ï¼šéšæœºæ¨èæŒ‡å®šæ•°é‡çš„ç”µå­ä¹¦ã€‚",
            "",
            "- **Archive.org**:",
            "  - `/archive search <å…³é”®è¯> [æ•°é‡]`ï¼šæœç´¢ Archive.org ç”µå­ä¹¦ã€‚ä¾‹å¦‚ï¼š`/archive search Python 20`ã€‚",
            "  - `/archive download <ä¸‹è½½é“¾æ¥>`ï¼šé€šè¿‡ Archive.org å¹³å°ä¸‹è½½ç”µå­ä¹¦ã€‚",
            "",
            "- **Z-Library**:",
            "  - `/zlib search <å…³é”®è¯> [æ•°é‡]`ï¼šæœç´¢ Z-Library çš„ç”µå­ä¹¦ã€‚ä¾‹å¦‚ï¼š`/zlib search Python 20`ã€‚",
            "  - `/zlib download <ID> <Hash>`ï¼šé€šè¿‡ Z-Library å¹³å°ä¸‹è½½ç”µå­ä¹¦ã€‚",
            "",
            "- **Liber3**:",
            "  - `/liber3 search <å…³é”®è¯> [æ•°é‡]`ï¼šæœç´¢ Liber3 å¹³å°ä¸Šçš„ç”µå­ä¹¦ã€‚ä¾‹å¦‚ï¼š`/liber3 search Python 20`ã€‚",
            "  - `/liber3 download <ID>`ï¼šé€šè¿‡ Liber3 å¹³å°ä¸‹è½½ç”µå­ä¹¦ã€‚",
            "",
            "- **é€šç”¨å‘½ä»¤**:",
            "  - `/ebooks help`ï¼šæ˜¾ç¤ºå½“å‰æ’ä»¶çš„å¸®åŠ©ä¿¡æ¯ã€‚",
            "  - `/ebooks search <å…³é”®è¯> [æ•°é‡]`ï¼šåœ¨æ‰€æœ‰æ”¯æŒçš„å¹³å°ä¸­åŒæ—¶æœç´¢ç”µå­ä¹¦ã€‚ä¾‹å¦‚ï¼š`/ebooks search Python 20`ã€‚",
            "  - `/ebooks download <URL/ID> [Hash]`ï¼šé€šç”¨çš„ç”µå­ä¹¦ä¸‹è½½æ–¹å¼ã€‚"
            "",
            "---",
            "ğŸ“’ **æ³¨æ„äº‹é¡¹**:",
            "- `æ•°é‡` ä¸ºå¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸º20ï¼Œç”¨äºé™åˆ¶æœç´¢ç»“æœçš„è¿”å›æ•°é‡ï¼Œæ•°é‡è¿‡å¤§å¯èƒ½å¯¼è‡´æ„é€ è½¬å‘æ¶ˆæ¯å¤±è´¥ã€‚",
            "- ä¸‹è½½æŒ‡ä»¤è¦æ ¹æ®æœç´¢ç»“æœï¼Œæä¾›æœ‰æ•ˆçš„ URLã€ID å’Œ Hash å€¼ã€‚",
            "- æ¨èåŠŸèƒ½ä¼šä»ç°æœ‰ä¹¦ç›®ä¸­éšæœºé€‰æ‹©ä¹¦ç±è¿›è¡Œå±•ç¤ºã€‚ï¼ˆä»…æ”¯æŒCalibre-Web)",
            "",
            "---",
            "ğŸŒ **æ”¯æŒå¹³å°**:",
            "- Calibre-Web",
            "- Liber3",
            "- Z-Library",
            "- Archive.org",
        ]
        yield event.plain_result("\n".join(help_msg))

    @ebooks.command("search")
    async def search_all_platforms(self, event: AstrMessageEvent, query: str = None, limit: str = "20"):
        """
        åŒæ—¶åœ¨æ‰€æœ‰æ”¯æŒçš„å¹³å°ä¸­æœç´¢ç”µå­ä¹¦ï¼Œå¼‚æ­¥è¿è¡Œï¼Œæ¯ä¸ªå¹³å°è¿”å›è‡ªå·±çš„æœç´¢ç»“æœæ ¼å¼ã€‚
        """
        if not query:
            yield event.plain_result("[ebooks] è¯·æä¾›ç”µå­ä¹¦å…³é”®è¯ä»¥è¿›è¡Œæœç´¢ã€‚")
            return

        if not (1 <= int(limit) <= 50):  # Validate limit
            yield event.plain_result("[ebooks] è¯·ç¡®è®¤æœç´¢è¿”å›ç»“æœæ•°é‡åœ¨ 1-50 ä¹‹é—´ã€‚")
            return

        async def consume_generator_async(gen):
            """å°†å¼‚æ­¥ç”Ÿæˆå™¨è½¬åŒ–ä¸ºæ ‡å‡†åç¨‹å¹¶è¿”å›ç»“æœï¼Œä»¥ç¡®ä¿ç±»å‹æ­£ç¡®"""
            return [item async for item in gen]

        tasks = []
        if self.config.get("enable_calibre", False):
            tasks.append(consume_generator_async(self.search_calibre(event, query, limit)))
        if self.config.get("enable_liber3", False):
            tasks.append(consume_generator_async(self.search_liber3(event, query, limit)))
        if self.config.get("enable_archive", False):
            tasks.append(consume_generator_async(self.search_archive(event, query, limit)))
        if self.config.get("enable_zlib", False):
            tasks.append(consume_generator_async(self.search_zlib(event, query, limit)))

        try:
            # å¹¶å‘è¿è¡Œæ‰€æœ‰ä»»åŠ¡
            search_results = await asyncio.gather(*tasks)

            # å°†ä»»åŠ¡ç»“æœé€ä¸€å‘é€
            for platform_results in search_results:  # éå†æ¯ä¸ªå¹³å°ç»“æœ
                for result in platform_results:  # éå†å…·ä½“æŸä¸ªå¹³å°çš„å•ä¸ªç»“æœ
                    try:
                        yield result
                    except Exception as e:
                        logger.error(f"[ebooks] å¤„ç†ç»“æœæ—¶å‡ºç°å¼‚å¸¸: {e}")
                        continue

        except Exception as e:
            logger.error(f"[ebooks] Error during multi-platform search: {e}")
            yield event.plain_result(f"[ebooks] æœç´¢ç”µå­ä¹¦æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚")

    @ebooks.command("download")
    async def download_all_platforms(self, event: AstrMessageEvent, arg1: str = None, arg2: str = None):
        """
        è‡ªåŠ¨è§£æå¹¶è¯†åˆ«è¾“å…¥ï¼Œè°ƒç”¨å¯¹åº”çš„å¹³å°ä¸‹è½½å®ç°ï¼Œå®Œæˆç”µå­ä¹¦çš„ä¸‹è½½å’Œå‘é€ã€‚

        :param arg1: ä¸»å‚æ•°ï¼Œå¯èƒ½æ˜¯é“¾æ¥ã€ID æˆ–å…¶ä»–æ ‡è¯†ç¬¦
        :param arg2: å¯é€‰å‚æ•°ï¼Œç”¨äºè¡¥å…… Z-Library ä¸‹è½½ä¸­çš„ Hash å€¼
        """
        if not arg1:
            yield event.plain_result("[ebooks] è¯·æä¾›æœ‰æ•ˆçš„ä¸‹è½½é“¾æ¥ã€ID æˆ–å‚æ•°ï¼")
            return

        try:
            # Z-Library ä¸‹è½½ (åŸºäº ID å’Œ Hash)
            if arg1 and arg2:  # æ£€æŸ¥ä¸¤ä¸ªå‚æ•°æ˜¯å¦éƒ½å­˜åœ¨
                try:
                    logger.info("[ebooks] æ£€æµ‹åˆ° Z-Library ID å’Œ Hashï¼Œå¼€å§‹ä¸‹è½½...")
                    async for result in self.download_zlib(event, arg1, arg2):
                        yield result
                except Exception as e:
                    yield event.plain_result(f"[ebooks] Z-Library å‚æ•°è§£æå¤±è´¥ï¼š{e}")
                return

            # Calibre-Web ä¸‹è½½ (åŸºäº OPDS é“¾æ¥)
            if arg1.startswith("http://") or arg1.startswith("https://"):
                if "/opds/download/" in arg1:
                    logger.info("[ebooks] æ£€æµ‹åˆ° Calibre-Web é“¾æ¥ï¼Œå¼€å§‹ä¸‹è½½...")
                    async for result in self.download_calibre(event, arg1):
                        yield result
                    return

                # Archive.org ä¸‹è½½
                if "archive.org/download/" in arg1:
                    logger.info("[ebooks] æ£€æµ‹åˆ° Archive.org é“¾æ¥ï¼Œå¼€å§‹ä¸‹è½½...")
                    async for result in self.download_archive(event, arg1):
                        yield result
                    return

            # Liber3 ä¸‹è½½
            if len(arg1) == 32 and re.match(r"^[A-Fa-f0-9]{32}$", arg1):  # ç¬¦åˆ Liber3 çš„ ID æ ¼å¼
                logger.info("[ebooks] â³ æ£€æµ‹åˆ° Liber3 IDï¼Œå¼€å§‹ä¸‹è½½...")
                async for result in self.download_liber3(event, arg1):
                    yield result
                return

            # æœªçŸ¥æ¥æºçš„è¾“å…¥
            yield event.plain_result(
                "[ebooks] æœªè¯†åˆ«çš„è¾“å…¥æ ¼å¼ï¼Œè¯·æä¾›ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€ï¼š\n"
                "- Calibre-Web ä¸‹è½½é“¾æ¥\n"
                "- Archive.org ä¸‹è½½é“¾æ¥\n"
                "- Liber3 32ä½ ID\n"
                "- Z-Library çš„ ID å’Œ Hash"
            )

        except Exception:
            # æ•è·å¹¶å¤„ç†è¿è¡Œæ—¶é”™è¯¯
            yield event.plain_result(f"[ebooks] ä¸‹è½½ç”µå­ä¹¦æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚")

    @llm_tool("search_ebooks")
    async def search_ebooks(self, event: AstrMessageEvent, query: str):
        """Search for eBooks across all supported platforms.

        When to use:
            This method performs a unified search across multiple platforms supported by this plugin,
            allowing users to find ebooks by title or keyword.
            Unless a specific platform is explicitly mentioned, this function should be used as the default means for searching books.


        Args:
            query (string): The keyword or book title for searching.
        """
        async for result in self.search_all_platforms(event, query, limit="20"):
            yield result

    @llm_tool("download_ebook")
    async def download_ebook(self, event: AstrMessageEvent, arg1: str, arg2: str = None):
        """Download eBooks by dispatching to the appropriate platform's download method.

        When to use:
            This method facilitates downloading of ebooks by automatically identifying the platform
            from the provided identifier (ID, URL, or Hash), and then calling the corresponding platform's download function.
            Unless the platform is specifically mentioned, this function serves as the default for downloading ebooks.

        Args:
            arg1 (string): Primary identifier, such as a URL or book ID.
            arg2 (string): Secondary input, such as a hash, required for Z-Library downloads.
        """
        async for result in self.download_all_platforms(event, arg1, arg2):
            yield result

    @command("test")
    async def test(self, event: AstrMessageEvent):
        yield event.chain_result([Image.fromURL("https://s3proxy.cdn-zlib.sk/covers400/c ollections/genesis/52f375b13029a198139b8101a6977c9aec5c4ad3e18ff8beaf4ea3c15615db9a.jpg ")])