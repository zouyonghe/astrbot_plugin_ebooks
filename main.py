import asyncio
import random
import re
import xml.etree.ElementTree as ET
from typing import Optional
from urllib.parse import quote_plus, urljoin, unquote, urlparse

import aiofiles
import aiohttp
from bs4 import BeautifulSoup

from astrbot.api.all import *
from astrbot.api.event.filter import *

TEMP_PATH = os.path.abspath("data/temp")

@register("ebooks", "buding", "ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ç”µå­ä¹¦æœç´¢å’Œä¸‹è½½æ’ä»¶", "1.0.0", "https://github.com/zouyonghe/astrbot_plugin_ebooks")
class ebooks(Star):
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config
        self.proxy = os.environ.get("https_proxy")
        os.makedirs(TEMP_PATH, exist_ok=True)

    async def _search_opds_call(self, query: str, limit: int = None):
        '''è°ƒç”¨ OPDS ç›®å½• API è¿›è¡Œç”µå­ä¹¦æœç´¢'''
        opds_url = self.config.get("opds_url", "http://127.0.0.1:8083")
        search_url = f"{opds_url}/opds/search/{query}"  # æ ¹æ®å®é™…è·¯å¾„æ„é€  API URL

        async with aiohttp.ClientSession() as session:
            async with session.get(search_url) as response:
                if response.status == 200:
                    content_type = response.headers.get("Content-Type", "")
                    if "application/atom+xml" in content_type:
                        data = await response.text()
                        return self._parse_opds_response(data, limit)  # è°ƒç”¨è§£ææ–¹æ³•
                    else:
                        logger.error(f"Unexpected content type: {content_type}")
                        return None
                else:
                    logger.error(f"OPDSæœç´¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                    return None

    def _parse_opds_response(self, xml_data: str, limit: int = None):
        '''è§£æ OPDS æœç´¢ç»“æœ XML æ•°æ®'''
        opds_url = self.config.get("opds_url", "http://127.0.0.1:8083")

        # ç§»é™¤éæ³•å­—ç¬¦
        xml_data = re.sub(r'[^\x09\x0A\x0D\x20-\uD7FF\uE000-\uFFFD]', '', xml_data)
        # æ¶ˆé™¤å¤šä½™ç©ºæ ¼
        xml_data = re.sub(r'\s+', ' ', xml_data)

        try:
            root = ET.fromstring(xml_data)  # æŠŠ XML è½¬æ¢ä¸ºå…ƒç´ æ ‘
            namespace = {"default": "http://www.w3.org/2005/Atom"}  # å®šä¹‰å‘½åç©ºé—´
            entries = root.findall("default:entry", namespace)  # æŸ¥æ‰¾å‰20ä¸ª <entry> èŠ‚ç‚¹

            results = []
            for entry in entries:
                # æå–ä¹¦ç±æ ‡é¢˜
                title_element = entry.find("default:title", namespace)
                title = title_element.text if title_element is not None else "æœªçŸ¥æ ‡é¢˜"

                # æå–ä½œè€…ï¼Œå¤šä½œè€…åœºæ™¯
                authors = []
                author_elements = entry.findall("default:author/default:name", namespace)
                for author in author_elements:
                    authors.append(author.text if author is not None else "æœªçŸ¥ä½œè€…")
                authors = ", ".join(authors) if authors else "æœªçŸ¥ä½œè€…"

                # æå–æè¿°ï¼ˆ<summary>ï¼‰
                summary_element = entry.find("default:summary", namespace)
                summary = summary_element.text if summary_element is not None else "æš‚æ— æè¿°"

                # æå–å‡ºç‰ˆæ—¥æœŸï¼ˆ<published>ï¼‰
                published_element = entry.find("default:published", namespace)
                published_date = published_element.text if published_element is not None else "æœªçŸ¥å‡ºç‰ˆæ—¥æœŸ"

                # æå–è¯­è¨€ï¼ˆ<dcterms:language>ï¼‰ï¼Œéœ€æ³¨æ„ namespace
                lang_element = entry.find("default:dcterms:language", namespace)
                language = lang_element.text if lang_element is not None else "æœªçŸ¥è¯­è¨€"

                # æå–å›¾ä¹¦å°é¢é“¾æ¥ï¼ˆrel="http://opds-spec.org/image"ï¼‰
                cover_element = entry.find("default:link[@rel='http://opds-spec.org/image']", namespace)
                cover_suffix = cover_element.attrib.get("href", "") if cover_element is not None else ""
                if cover_suffix and re.match(r"^/opds/cover/\d+$", cover_suffix):
                    cover_link = urljoin(opds_url, cover_suffix)
                else:
                    cover_link = ""

                # æå–å›¾ä¹¦ç¼©ç•¥å›¾é“¾æ¥ï¼ˆrel="http://opds-spec.org/image/thumbnail"ï¼‰
                thumbnail_element = entry.find("default:link[@rel='http://opds-spec.org/image/thumbnail']", namespace)
                thumbnail_suffix = thumbnail_element.attrib.get("href", "") if thumbnail_element is not None else ""
                if thumbnail_suffix and re.match(r"^/opds/cover/\d+$", thumbnail_suffix):
                    thumbnail_link = urljoin(opds_url, thumbnail_suffix)
                else:
                    thumbnail_link = ""

                # æå–ä¸‹è½½é“¾æ¥åŠå…¶æ ¼å¼ï¼ˆrel="http://opds-spec.org/acquisition"ï¼‰
                acquisition_element = entry.find("default:link[@rel='http://opds-spec.org/acquisition']", namespace)
                if acquisition_element is not None:
                    download_suffix = acquisition_element.attrib.get("href", "") if acquisition_element is not None else ""
                    if download_suffix and re.match(r"^/opds/download/\d+/[\w]+/$", download_suffix):
                        download_link = urljoin(opds_url, download_suffix)
                    else:
                        download_link = ""
                    file_type = acquisition_element.attrib.get("type", "æœªçŸ¥æ ¼å¼")
                    file_size = acquisition_element.attrib.get("length", "æœªçŸ¥å¤§å°")
                else:
                    download_link = ""
                    file_type = "æœªçŸ¥æ ¼å¼"
                    file_size = "æœªçŸ¥æ ¼å¼"

                # æ„å»ºç»“æœ
                results.append({
                    "title": title,
                    "authors": authors,
                    "summary": summary,
                    "published_date": published_date,
                    "language": language,
                    "cover_link": cover_link,
                    "thumbnail_link": thumbnail_link,
                    "download_link": download_link,
                    "file_type": file_type,
                    "file_size": file_size
                })

            return results[:limit]
        except ET.ParseError as e:
            logger.error(f"è§£æ OPDS å“åº”å¤±è´¥: {e}")
            return None

    async def _show_opds_result(self, event: AstrMessageEvent, results: list, guidance: str = None):
        if not results:
            yield event.plain_result("æœªæ‰¾åˆ°ç›¸å…³çš„ç”µå­ä¹¦ã€‚")

        if len(results) == 1:
            item = results[0]
            chain = [
                Plain(f"{item['title']}")
            ]
            if item.get("cover_link"):
                chain.append(Image.fromURL(item["cover_link"]))
            else:
                chain.append(Plain("\n"))
            chain.append(Plain(f"ä½œè€…: {item.get('authors', 'æœªçŸ¥ä½œè€…')}"))
            chain.append(Plain(f"\nç®€ä»‹: {item.get('summary', 'æš‚æ— ç®€ä»‹')}"))
            chain.append(Plain(f"\né“¾æ¥(ç”¨äºä¸‹è½½): {item.get('download_link', 'æœªçŸ¥é“¾æ¥')}"))
            yield event.chain_result(chain)
        else:
            ns = Nodes([])
            if guidance:
                ns.nodes.append(Node(uin=event.get_self_id(), name="OPDS", content=guidance))
            for idx, item in enumerate(results):
                chain = [Plain(f"{item['title']}")]
                if item.get("cover_link"):
                    chain.append(Image.fromURL(item["cover_link"]))
                else:
                    chain.append(Plain("\n"))
                chain.append(Plain(f"ä½œè€…: {item.get('authors', 'æœªçŸ¥ä½œè€…')}"))
                chain.append(Plain(f"\nç®€ä»‹: {item.get('summary', 'æš‚æ— ç®€ä»‹')}"))
                chain.append(Plain(f"\né“¾æ¥(ç”¨äºä¸‹è½½): {item.get('download_link', 'æœªçŸ¥é“¾æ¥')}"))

                node = Node(
                    uin=event.get_self_id(),
                    name="OPDS",
                    content=chain
                )
                ns.nodes.append(node)
            yield event.chain_result([ns])

    def to_string(self, results: list) -> str:
        """
        å°†ç»“æœåˆ—è¡¨ä¸­çš„æ‰€æœ‰é¡¹ç›®æ‹¼æ¥ä¸ºå­—ç¬¦ä¸²ã€‚

        Args:
            results (list): åŒ…å«å­—å…¸çš„ç»“æœåˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå­—å…¸è¡¨ç¤ºä¸€ä¸ªæ¡ç›®ã€‚

        Returns:
            str: æ‹¼æ¥åçš„æ€»å­—ç¬¦ä¸²è¡¨ç¤ºç»“æœã€‚
        """
        if not results:
            return "æ²¡æœ‰æ‰¾åˆ°ç»“æœã€‚"

        result_strings = []
        for item in results:
            part = f"æ ‡é¢˜: {item.get('title', 'æœªçŸ¥æ ‡é¢˜')}\n"
            part += f"ä½œè€…: {item.get('authors', 'æœªçŸ¥ä½œè€…')}\n"
            part += f"æè¿°: {item.get('summary', 'æš‚æ— æè¿°')}\n"
            part += f"é“¾æ¥: {item.get('download_link', 'æ— ä¸‹è½½é“¾æ¥')}\n"
            result_strings.append(part)

        return "\n\n".join(result_strings)

    @command_group("opds")
    def opds(self):
        pass

    @opds.command("search")
    async def search_opds(self, event: AstrMessageEvent, query: str=None):
        '''æœç´¢ OPDS ç”µå­ä¹¦ç›®å½•'''
        if not query:
            yield event.plain_result("è¯·è¾“å…¥æœç´¢å…³é”®è¯ã€‚")
            return

        try:
            results = await self._search_opds_call(quote_plus(query))  # è°ƒç”¨æœç´¢æ–¹æ³•
            if not results or len(results) == 0:
                yield event.plain_result("æœªæ‰¾åˆ°ç›¸å…³çš„ç”µå­ä¹¦ã€‚")
            else:
                async for result in self._show_opds_result(event, results):
                    yield result
        except Exception as e:
            logger.error(f"OPDSæœç´¢å¤±è´¥: {e}")
            yield event.plain_result("æœç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")

    @opds.command("help")
    async def show_help(self, event: AstrMessageEvent):
        '''æ˜¾ç¤º OPDS æ’ä»¶å¸®åŠ©ä¿¡æ¯'''
        help_msg = [
            "ğŸ“š OPDS æ’ä»¶ä½¿ç”¨æŒ‡å—",
            "è¯¥æ’ä»¶é€šè¿‡æ ‡å‡†çš„ OPDS åè®®ä¸ç”µå­ä¹¦ç›®å½•äº¤äº’ï¼Œæ”¯æŒæœç´¢ã€ä¸‹è½½å’Œæ¨èåŠŸèƒ½ã€‚",
            "",
            "ğŸ”§ **å‘½ä»¤åˆ—è¡¨**:",
            "- `/opds search [å…³é”®è¯]`ï¼šæœç´¢ OPDS ç›®å½•ä¸­çš„ç”µå­ä¹¦ã€‚ä¾‹å¦‚ï¼š`/opds search Python`ã€‚",
            "- `/opds download [ä¸‹è½½é“¾æ¥/ä¹¦å]`ï¼šé€šè¿‡ OPDS ç›´æ¥ä¸‹è½½ç”µå­ä¹¦ã€‚ä¾‹å¦‚ï¼š`/opds download http://example.com/path/to/book`ã€‚",
            "- `/opds recommend [æ•°é‡]`ï¼šéšæœºæ¨èæŒ‡å®šæ•°é‡çš„ç”µå­ä¹¦ã€‚ä¾‹å¦‚ï¼š`/opds recommend 5`ã€‚",
            "- `/opds help`ï¼šæ˜¾ç¤ºå½“å‰æ’ä»¶çš„å¸®åŠ©ä¿¡æ¯ï¼ˆå³æ­¤å†…å®¹ï¼‰ã€‚",
            "",
            "ğŸ“’ **æ³¨æ„äº‹é¡¹**:",
            "- ä¸‹è½½æŒ‡ä»¤æ”¯æŒç›´æ¥è¾“å…¥ç”µå­ä¹¦çš„ä¸‹è½½é“¾æ¥æˆ–é€šè¿‡ç²¾ç¡®ä¹¦ååŒ¹é…æ¥ä¸‹è½½ã€‚",
            "- ä½¿ç”¨æ¨èåŠŸèƒ½æ—¶ï¼Œæ’ä»¶ä¼šä»ç°æœ‰ä¹¦ç›®ä¸­éšæœºé€‰æ‹©ä¹¦ç±ã€‚",
        ]
        yield event.plain_result("\n".join(help_msg))

    @opds.command("download")
    async def download(self, event: AstrMessageEvent, ebook_url: str = None):
        '''é€šè¿‡ OPDS åè®®ä¸‹è½½ç”µå­ä¹¦'''
        if not ebook_url:
            yield event.plain_result("è¯·è¾“å…¥ç”µå­ä¹¦çš„ä¸‹è½½é“¾æ¥ã€‚")
            return

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(ebook_url) as response:
                    if response.status == 200:
                        # ä» Content-Disposition æå–æ–‡ä»¶å
                        content_disposition = response.headers.get("Content-Disposition")
                        book_name = None

                        if content_disposition:
                            logger.debug(f"Content-Disposition: {content_disposition}")

                            # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰ filename*= æ¡ç›®
                            book_name_match = re.search(r'filename\*=(?:UTF-8\'\')?([^;]+)', content_disposition)
                            if book_name_match:
                                book_name = book_name_match.group(1)
                                book_name = unquote(book_name)  # è§£ç  URL ç¼–ç çš„æ–‡ä»¶å
                            else:
                                # å¦‚æœæ²¡æœ‰ filename*ï¼Œåˆ™æŸ¥æ‰¾æ™®é€šçš„ filename
                                book_name_match = re.search(r'filename=["\']?([^;\']+)["\']?', content_disposition)
                                if book_name:
                                    book_name = book_name_match.group(1)

                        # å¦‚æœæœªè·å–åˆ°æ–‡ä»¶åï¼Œä½¿ç”¨é»˜è®¤å€¼
                        if not book_name or book_name.strip() == "":
                            logger.error(f"æ— æ³•æå–ä¹¦åï¼Œç”µå­ä¹¦åœ°å€: {ebook_url}")
                            yield event.plain_result("æ— æ³•æå–ä¹¦åï¼Œå–æ¶ˆå‘é€ç”µå­ä¹¦ã€‚")
                            return 
                            
                        # å‘é€æ–‡ä»¶åˆ°ç”¨æˆ·
                        file = File(name=book_name, file=ebook_url)
                        yield event.chain_result([file])
                    else:
                        yield event.plain_result(f"æ— æ³•ä¸‹è½½ç”µå­ä¹¦ï¼ŒçŠ¶æ€ç : {response.status}")
        except Exception as e:
            logger.error(f"ä¸‹è½½å¤±è´¥: {e}")
            yield event.plain_result("ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")

    @opds.command("recommend")
    async def recommend(self, event: AstrMessageEvent, n: int):
        '''éšæœºæ¨è n æœ¬ä¹¦ç±'''
        try:
            # è°ƒç”¨ OPDS æœç´¢æ¥å£ï¼Œé»˜è®¤æœç´¢æ‰€æœ‰ä¹¦ç±
            query = "*"  # ç©ºæŸ¥è¯¢ï¼Œå¯ä»¥è°ƒå‡ºå®Œæ•´ä¹¦ç›®
            results = await self._search_opds_call(query)

            # æ£€æŸ¥æ˜¯å¦æœ‰ä¹¦ç±å¯ä¾›æ¨è
            if not results:
                yield event.plain_result("æœªæ‰¾åˆ°ä»»ä½•å¯æ¨èçš„ç”µå­ä¹¦ã€‚")
                return

            # é™åˆ¶æ¨èæ•°é‡ï¼Œé˜²æ­¢è¶…å‡ºå®é™…ä¹¦ç±æ•°é‡
            if n > len(results):
                n = len(results)

            # éšæœºé€‰æ‹© n æœ¬ä¹¦ç±
            recommended_books = random.sample(results, n)

            # æ˜¾ç¤ºæ¨èä¹¦ç±
            guidance = f"å¦‚ä¸‹æ˜¯éšæœºæ¨èçš„ {n} æœ¬ç”µå­ä¹¦"
            async for result in self._show_opds_result(event, recommended_books, guidance):
                yield result

        except Exception as e:
            logger.error(f"æ¨èä¹¦ç±æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            yield event.plain_result("æ¨èéšæœºä¹¦ç±æ—¶å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")

    @llm_tool("opds_search_books")
    async def search_books(self, event: AstrMessageEvent, query: str):
        """Search books by keywords or title through OPDS.
        When to use:
            Use this method to search for books in the OPDS catalog when user knows the title or keyword.
            This method cannot be used for downloading books and should only be used for searching purposes.
    
        Args:
            query (string): The search keyword or title to find books in the OPDS catalog.
    
        """
        async for result in self.search_opds(event, query):
            yield result

    @llm_tool("opds_download_book")
    async def download_book(self, event: AstrMessageEvent, book_identifier: str):
        """Download a book by a precise name or URL through OPDS.
        When to use:
            Use this method to download a specific book by its name or when a direct download link is available.
    
        Args:
            book_identifier (string): The book name (exact match) or the URL of the book link.
    
        """
        try:
            ebook_url = ""
            # First, determine if the identifier is a URL or a book name
            if book_identifier.lower().startswith("http://") or book_identifier.lower().startswith("https://"):
                ebook_url = book_identifier
            else:
                # Search the book by name
                results = await self._search_opds_call(quote_plus(book_identifier))
                matched_books = [
                    book for book in results if book_identifier.lower() in book["title"].lower()
                ]

                if len(matched_books) == 1:
                    ebook_url = matched_books[0]["download_link"]
                elif len(matched_books) > 1:
                    async for result in self._show_opds_result(event, results, guidance="è¯·ä½¿ç”¨é“¾æ¥ä¸‹è½½ç”µå­ä¹¦ã€‚\n"):
                        yield result
                else:
                    yield event.plain_result("æœªèƒ½æ‰¾åˆ°åŒ¹é…çš„ç”µå­ä¹¦ï¼Œè¯·æä¾›å‡†ç¡®ä¹¦åæˆ–ç”µå­ä¹¦ä¸‹è½½é“¾æ¥ã€‚")
                    return
            async for result in self.download(event, ebook_url):
                yield result
        except Exception as e:
            logger.error(f"å¤„ç†ä¹¦ç±æ¥æ”¶è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            yield event.plain_result("å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥è¾“å…¥æ˜¯å¦æ­£ç¡®ã€‚")

    @llm_tool("opds_recommend_books")
    async def recommend_books(self, event: AstrMessageEvent, n: str = "5"):
        """Randomly recommend n books from the OPDS catalog.
        When to use:
            Use this method to get a random selection of books when users are unsure what to read.
    
        Args:
            n (string): Number of books to recommend (default is 5).
        """
        async for result in self.recommend(event, int(n)):
            yield result
            
    async def get_liber3_book_details(self, book_ids: list) -> Optional[dict]:
        """é€šè¿‡ä¹¦ç± ID è·å–è¯¦ç»†ä¿¡æ¯"""
        detail_url = "https://lgate.glitternode.ru/v1/book"
        headers = {"Content-Type": "application/json"}
        payload = {"book_ids": book_ids}

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(detail_url, headers=headers, json=payload, proxy=self.proxy) as response:
                    if response.status == 200:
                        data = await response.json()
                        return data.get("data", {}).get("book", {})
                    else:
                        logger.error(f"è¯·æ±‚ä¹¦ç±è¯¦ç»†ä¿¡æ¯å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None
        except aiohttp.ClientError as e:
            logger.error(f"HTTP å®¢æˆ·ç«¯é”™è¯¯: {e}")
        except Exception as e:
            logger.error(f"å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")

        return None
    
    async def search_liber3_books_with_details(self, word: str) -> Optional[dict]:
        """æœç´¢ä¹¦ç±å¹¶è·å–å‰ 50 æœ¬ä¹¦ç±çš„è¯¦ç»†ä¿¡æ¯"""
        search_url = "https://lgate.glitternode.ru/v1/searchV2"
        headers = {"Content-Type": "application/json"}
        payload = {
            "address": "",
            "word": word
        }

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(search_url, headers=headers, json=payload, proxy=self.proxy) as response:
                    if response.status == 200:
                        data = await response.json()

                        # è·å–ä¹¦ç± ID åˆ—è¡¨
                        book_data = data["data"].get("book", [])
                        if not book_data:
                            logger.info("æœªæ‰¾åˆ°ç›¸å…³ä¹¦ç±ã€‚")
                            return None

                        book_ids = [item.get("id") for item in book_data[:50]]  # è·å–å‰ 50 æœ¬ä¹¦ç±çš„ ID
                        if not book_ids:
                            logger.info("æœªèƒ½æå–ä¹¦ç± IDã€‚")
                            return None

                        # è°ƒç”¨è¯¦ç»†ä¿¡æ¯ API
                        detailed_books = await self.get_liber3_book_details(book_ids)
                        if not detailed_books:
                            logger.info("æœªè·å–ä¹¦ç±è¯¦ç»†ä¿¡æ¯ã€‚")
                            return None

                        # è¿”å›åŒ…å«æœç´¢ç»“æœåŠè¯¦ç»†ä¿¡æ¯çš„æ•°æ®
                        return {
                            "search_results": book_data[:50],  # åŸå§‹çš„å‰ 50 æœ¬æœç´¢ç»“æœ
                            "detailed_books": detailed_books  # å®Œæ•´è¯¦ç»†ä¿¡æ¯
                        }

                    else:
                        logger.error(f"è¯·æ±‚ä¹¦ç±æœç´¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None
        except aiohttp.ClientError as e:
            logger.error(f"HTTP å®¢æˆ·ç«¯é”™è¯¯: {e}")
        except Exception as e:
            logger.error(f"å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")

        return None

    @command_group("liber3")
    def liber3(self):
        pass

    @liber3.command("search")
    async def search_liber3(self, event: AstrMessageEvent, query: str = None):
        """æœç´¢ä¹¦ç±å¹¶è¾“å‡ºè¯¦ç»†ä¿¡æ¯"""
        if not query:
            yield event.plain_result("è¯·æä¾›ä¹¦ç±å…³é”®è¯ä»¥è¿›è¡Œæœç´¢ã€‚")
            return

        logger.info(f"Received book search query: {query}")
        results = await self.search_liber3_books_with_details(query)

        if not results:
            yield event.plain_result("æœªæ‰¾åˆ°ç›¸å…³ä¹¦ç±ã€‚")
            return

        # è¾“å‡ºæœç´¢ç»“æœå’Œè¯¦ç»†ä¿¡æ¯
        search_results = results.get("search_results", [])
        detailed_books = results.get("detailed_books", {})

        ns = Nodes([])

        for index, book in enumerate(search_results, start=1):
            book_id = book.get("id")
            detail = detailed_books.get(book_id, {}).get("book", {})

            chain = [
                Plain(f"æ ‡é¢˜: {book.get('title', 'æœªçŸ¥')}\n"),
                Plain(f"ä½œè€…: {book.get('author', 'æœªçŸ¥')}\n"),
                Plain(f"è¯­è¨€: {detail.get('language', 'æœªçŸ¥')}\n"),
                Plain(f"æ–‡ä»¶å¤§å°: {detail.get('filesize', 'æœªçŸ¥')}\n"),
                Plain(f"æ–‡ä»¶ç±»å‹: {detail.get('extension', 'æœªçŸ¥')}\n"),
                Plain(f"å¹´ä»½: {detail.get('year', 'æœªçŸ¥')}\n"),
                Plain(f"ID(ç”¨äºä¸‹è½½): {book_id}"),
            ]

            node = Node(
                uin=event.get_self_id(),
                name="Liber3",
                content=chain
            )
            ns.nodes.append(node)

        yield event.chain_result([ns])

    @liber3.command("download")
    async def download_liber3(self, event: AstrMessageEvent, book_id: str = None):
        if not book_id:
            yield event.plain_result("è¯·æä¾›æœ‰æ•ˆçš„ä¹¦ç± IDã€‚")
            return

        # è·å–è¯¦ç»†çš„ä¹¦ç±ä¿¡æ¯
        book_details = await self.get_liber3_book_details([book_id])
        if not book_details or book_id not in book_details:
            yield event.plain_result("æ— æ³•è·å–ä¹¦ç±å…ƒä¿¡æ¯ï¼Œè¯·æ£€æŸ¥ä¹¦ç± ID æ˜¯å¦æ­£ç¡®ã€‚")
            return

        # æå–ä¹¦ç±ä¿¡æ¯
        book_info = book_details[book_id].get("book", {})
        book_name = book_info.get("title", "unknown_book").replace(" ", "_")
        extension = book_info.get("extension", "unknown_extension")
        ipfs_cid = book_info.get("ipfs_cid", "")

        if not ipfs_cid or not extension:
            yield event.plain_result("ä¹¦ç±ä¿¡æ¯ä¸è¶³ï¼Œæ— æ³•å®Œæˆä¸‹è½½ã€‚")
            return

        # æ„é€ ä¸‹è½½é“¾æ¥
        ebook_url = f"https://gateway-ipfs.st/ipfs/{ipfs_cid}?filename={book_name}.{extension}"

        # ä½¿ç”¨ File å¯¹è±¡ï¼Œé€šè¿‡ chain_result ä¸‹è½½
        file = File(name=f"{book_name}.{extension}", file=ebook_url)
        yield event.chain_result([file])

    @llm_tool("search_liber3_books")
    async def search_liber3_books(self, event: AstrMessageEvent, query: str):
        """Search for books using Liber3 API and return a detailed result list.

        When to use:
            Invoke this tool to locate books based on keywords or titles from Liber3's library.

        Args:
            query (string): The keyword or title to search for books.
        """
        async for result in self.search_liber3(event, query):
            yield result

    @llm_tool("download_liber3_book")
    async def download_liber3_book(self, event: AstrMessageEvent, book_id: str):
        """Download a book using Liber3's API via its unique ID.

        When to use:
            This tool allows you to retrieve a Liber3 book using the unique ID and download it.

        Args:
            book_id (string): A valid Liber3 book ID required to download a book.
        """
        async for result in self.download_liber3(event, book_id):
            yield result

    async def search_archive_books(self, query: str, limit: int = 20):
        """é€šè¿‡ archive API æœç´¢ç”µå­ä¹¦ï¼Œå¹¶ç­›é€‰ PDF æˆ– EPUB æ ¼å¼çš„æ–‡ä»¶ã€‚
            Args:
                query (str): æœç´¢çš„æ ‡é¢˜å…³é”®å­—
                limit (int): è¿”å›çš„æœ€å¤šç»“æœæ•°é‡
            Returns:
                list: åŒ…å«æ»¡è¶³æ¡ä»¶çš„ä¹¦ç±ä¿¡æ¯å’Œä¸‹è½½é“¾æ¥çš„åˆ—è¡¨
            """
        base_search_url = "https://archive.org/advancedsearch.php"
        base_metadata_url = "https://archive.org/metadata/"
        formats = ("pdf", "epub")  # æ”¯æŒçš„ç”µå­ä¹¦æ ¼å¼

        params = {
            "q": f'title:"{query}" mediatype:texts',  # æ ¹æ®æ ‡é¢˜æœç´¢
            "fl[]": "identifier,title",  # è¿”å› identifier å’Œ title å­—æ®µ
            "sort[]": "downloads desc",  # æŒ‰ä¸‹è½½é‡æ’åº
            "rows": limit,  # æœ€å¤§ç»“æœæ•°é‡
            "page": 1,
            "output": "json"  # è¿”å›æ ¼å¼ä¸º JSON
        }

        async with aiohttp.ClientSession() as session:
            # 1. è°ƒç”¨ Archive æœç´¢ API
            response = await session.get(base_search_url, params=params, proxy=self.proxy)
            if response.status != 200:
                logger.error(f"æœç´¢ Archive å‡ºç°é”™è¯¯ï¼ŒçŠ¶æ€ç : {response.status}")
                return []

            result_data = await response.json()
            docs = result_data.get("response", {}).get("docs", [])
            if not docs:
                logger.info("æœªæ‰¾åˆ°ä¸å…³é”®è¯åŒ¹é…çš„ç”µå­ä¹¦ã€‚")
                return []

            # 2. æ ¹æ® identifier æå–å…ƒæ•°æ®
            tasks = [
                self._fetch_metadata(session, base_metadata_url + doc["identifier"], formats) for doc in docs
            ]
            metadata_results = await asyncio.gather(*tasks)

            # 3. ç­›é€‰æœ‰æ•ˆç»“æœå¹¶è¿”å›
            books = [
                {
                    "title": doc.get("title"),
                    "authors": metadata.get("authors"),
                    "download_url": metadata.get("download_url"),
                    "description": metadata.get("description")
                }
                for doc, metadata in zip(docs, metadata_results) if metadata
            ]
            return books

    async def _fetch_metadata(self, session: aiohttp.ClientSession, url: str, formats: tuple) -> dict:
        """ä» Metadata API è·å–æŒ‡å®šæ ¼å¼çš„ç”µå­ä¹¦ä¿¡æ¯ï¼ŒåŒæ—¶æå–å°é¢å’Œç®€ä»‹ã€‚
            Args:
                session (aiohttp.ClientSession): aiohttp ä¼šè¯
                url (str): Metadata API çš„ URL
                formats (tuple): éœ€è¦çš„æ–‡ä»¶æ ¼å¼ï¼ˆå¦‚ PDF, EPUBï¼‰
            Returns:
                dict: åŒ…å«ä¸‹è½½é“¾æ¥ã€æ–‡ä»¶ç±»å‹ã€å°é¢å’Œç®€ä»‹çš„å­—å…¸
            """
        try:
            response = await session.get(url, proxy=self.proxy)
            if response.status != 200:
                logger.error(f"è·å– Metadata æ•°æ®å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                return {}

            metadata = await response.json()
            identifier = metadata.get("metadata", {}).get("identifier", None)
            files = metadata.get("files", [])
            description = metadata.get("metadata", {}).get("description", None)
            authors = metadata.get("metadata", {}).get("creator", None)

            # åˆ¤æ–­å¹¶è§£æç®€ä»‹
            if isinstance(description, str):
                if self._is_html(description):
                    description = self._parse_html_to_text(description)
                else:
                    description = description.strip()
                description = description[:200] + "..." if len(description) > 200 else description
            else:
                description = "æ— ç®€ä»‹"

            # æå–ç‰¹å®šæ ¼å¼æ–‡ä»¶ï¼ˆå¦‚ PDF å’Œ EPUBï¼‰
            for file in files:
                if any(file.get("name", "").lower().endswith(fmt) for fmt in formats):
                    return {
                        "download_url": f"https://archive.org/download/{identifier}/{file['name']}",
                        "description": description,
                        "authors": authors,
                    }

        except Exception as e:
            logger.error(f"è·å– Metadata æ•°æ®æ—¶å‡ºç°é”™è¯¯: {e}")
        return {}

    def _is_html(self, content):
        """åˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦ä¸º HTML æ ¼å¼"""
        if not isinstance(content, str):
            return False
        return bool(re.search(r'<[^>]+>', content))

    def _parse_html_to_text(self, html_content):
        """å°† HTML å†…å®¹è§£æä¸ºçº¯æ–‡æœ¬"""
        soup = BeautifulSoup(html_content, "html.parser")
        return soup.get_text().strip()

    @command_group("archive")
    def archive(self):
        pass

    @archive.command("search")
    async def search_archive(self, event: AstrMessageEvent, query: str = None, limit: str = "20"):
        """é€šè¿‡ archive å¹³å°æœç´¢ç”µå­ä¹¦ï¼Œå¹¶è¿‡æ»¤æ”¯æŒçš„æ ¼å¼ã€‚
            Args:
                query (str): æœç´¢çš„ä¹¦ç±æ ‡é¢˜æˆ–å…³é”®è¯ï¼ˆå¿…é¡»æä¾›ï¼‰
                limit (str): ç»“æœæ•°é‡é™åˆ¶ï¼Œé»˜è®¤ä¸º 20
            """
        if not query:
            yield event.plain_result("è¯·è¾“å…¥è¦æœç´¢çš„æ ‡é¢˜æˆ–å…³é”®è¯ã€‚")
            return

        try:
            limit = int(limit) if limit.isdigit() else 20  # é»˜è®¤æœ€å¤šè¿”å› 20 ä¸ªç»“æœ
            results = await self.search_archive_books(query, limit)

            if not results:
                yield event.plain_result("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç”µå­ä¹¦ã€‚")
                return

            # è¿”å›ç»“æœåˆ°ç”¨æˆ·
            ns = Nodes([])
            for idx, book in enumerate(results, start=1):
                chain = [
                    Plain(f"{book['title']}\n"),
                    Plain(f"ä½œè€…: {book.get('authors')}\n"),
                    Plain(f"ç®€ä»‹: {book.get('description', 'æ— ç®€ä»‹')}\n"),
                    Plain(f"é“¾æ¥(ç”¨äºä¸‹è½½): {book.get('download_url', 'æœªçŸ¥')}")
                ]
                node = Node(uin=event.get_self_id(), name="Archive", content=chain)
                ns.nodes.append(node)

            yield event.chain_result([ns])

        except Exception as e:
            logger.error(f"å¤„ç† Archive æœç´¢è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            yield event.plain_result("æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")

    @archive.command("download")
    async def download_archive_book(self, event: AstrMessageEvent, download_url: str = None):
        """é€šè¿‡æä¾›çš„é“¾æ¥ä¸‹è½½ Archive å¹³å°ä¸Šçš„ç”µå­ä¹¦ã€‚
            Args:
                download_url (str): ç”µå­ä¹¦çš„ä¸‹è½½ URL
        """
        if not download_url:
            yield event.plain_result("è¯·æä¾›æœ‰æ•ˆçš„ä¸‹è½½é“¾æ¥ã€‚")
            return

        try:
            async with aiohttp.ClientSession() as session:
                # å‘å‡º GET è¯·æ±‚å¹¶è·Ÿéšè·³è½¬
                async with session.get(download_url, allow_redirects=True, proxy=self.proxy) as response:
                    if response.status == 200:
                        # æ‰“å°è·³è½¬åçš„æœ€ç»ˆåœ°å€
                        ebook_url = str(response.url)
                        logger.info(f"è·³è½¬åçš„ä¸‹è½½åœ°å€: {ebook_url}")

                        # ä» Content-Disposition æå–æ–‡ä»¶å
                        content_disposition = response.headers.get("Content-Disposition", "")
                        book_name = None

                        # æå–æ–‡ä»¶å
                        if content_disposition:
                            logger.debug(f"Content-Disposition: {content_disposition}")
                            book_name_match = re.search(r'filename\*=(?:UTF-8\'\')?([^;]+)', content_disposition)
                            if book_name_match:
                                book_name = unquote(book_name_match.group(1))
                            else:
                                book_name_match = re.search(r'filename=["\']?([^;\']+)["\']?', content_disposition)
                                if book_name_match:
                                    book_name = book_name_match.group(1)

                        # å¦‚æœæœªæå–åˆ°æ–‡ä»¶åï¼Œå°è¯•ä» URL æå–
                        if not book_name or book_name.strip() == "":
                            parsed_url = urlparse(ebook_url)
                            book_name = os.path.basename(parsed_url.path) or "unknown_book"

                        # å°†ä¸´æ—¶æ–‡ä»¶è·¯å¾„ä¼ é€’ç»™ File
                        file = File(name=book_name, file=ebook_url)
                        yield event.chain_result([file])
                    else:
                        yield event.plain_result(f"æ— æ³•ä¸‹è½½ç”µå­ä¹¦ï¼ŒçŠ¶æ€ç : {response.status}")
        except Exception as e:
            logger.error(f"ä¸‹è½½å¤±è´¥: {e}")
            yield event.plain_result(f"ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{e}")


